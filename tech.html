<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Assignment 2 - Team Project
    </title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <header>
      <a href="index.html"class="header-brand">OTOD Tech
      </a>
      <nav>
        <ul>
          <li>
            <a href="about.html">Meet the Team
            </a>
          </li>
          <li>
            <a href="profiles.html">Team Profile
            </a>
          </li>
          <li>
            <a href="tech.html">IT Technologies
            </a>
          </li>
          <li>
            <a href="job.html">IT Industry
            </a>
          </li>
          <li>
            <a href="project.html">Team Project
            </a>
          </li>
          <li>
            <a href="review.html">Team Review
            </a>
          </li>
        </ul>
        <a href="about.html" class="header-profiles">Contact the Team
        </a>
      </nav>
    </header>
    <main>
      <h2>IT Technologies
      </h2>
      <div class="wrapper">
        <div class="wrapper">
          <article class="tech-pages">
          <br>
            <centre><img src="img/AV.png" alt="AV" width="460" height="345"></centre>
            <h1>Autonomous Vehicles (AV)</h1>
            <p>Autonomous vehicles (AV) also referred to as driverless cars, are able to sense the surrounding environment and navigate safely with little to no human intervention. They rely on sensors, complex algorithms, actuators (component of a machine that is responsible for movement and control of the car), powerful processors and machine learning systems. These cars are able to be in full control with or without a human passenger.</p>
            <p>These cars contain a variety of sensors located throughout the different parts of the vehicle. This includes video cameras to detect traffic lights, track other vehicles, understand road signs and most importantly, look out for pedestrians. They utilise radar sensors to monitor nearby vehicles. Lidar sensors (light detection and ranging sensors) indicates and measures distance, detect road edges and lane markings by bouncing light off the car’s surroundings. The detection of curbs and other cars when parking occur via the ultrasonic sensors inside of the wheels.</p>
            <p>Advanced software then processes all of the sensory input, plots a journey, and sends the instructions to the actuators which controls steering, braking and acceleration. The car then follows traffic rules and navigates obstacles through an intricate set of hard-coded rules, predictive modelling, object recognition and obstacle avoidance algorithms.</p>
            <p>Though some may be intrigued and excited about owning a fully autonomous car, several countries are still testing the reliability and safety of them. Some of the top challenges seem to be environmental, philosophical and legislative.  So, they won’t be available to the general public for a number of years yet.</p>
            <p>Some of the unknowns include, weather conditions such as heavy rains and snow and the effects on camera visibility and reliability of the sensors to track lane markings. Potential issues regarding the expense of Lidar, and will other autonomous cars travelling on the same road interfere with the lidar signals.  Will travelling through tunnels and over bridges be an issue?  What about bumper to bumper traffic?  Can the autonomous car regulate correctly?  Then there is the question around accident liability, who is at fault? The manufacturer? The human passenger? Another concern is the difference between human intelligence and artificial intelligence when it comes to the subtle cues and life-saving instincts that humans may have over a machine.</p>
            <p>As of 2021, there are no companies that offer a fully autonomous car to the public. There are companies introducing very limited technologies for public accessibility such as sophisticated cruise control systems, and then there are companies that have managed to introduce almost autonomous technology, but under extremely restricted circumstances, such as shuttle buses on college campuses.</p>
            <p style="margin-left:10%; margin-right:10%;">Some of the big car companies have disputed some of the technology that makes up the autonomous vehicle such as the lidar sensors, but technology that is not in dispute is machine learning and AI. Most companies have constructed a simulation environment – a virtual city as it were – to run their cars through and quickly test rare scenarios or hardware tweaks. Think of it as Tron meets calculus homework. Any company who has built such a simulation has invariably run many more “miles” inside the virtual world than in the real one. What enables these simulations to be so valuable is incredibly detailed mapping of intersections, routes, and even whole cities. (Kaslikowski 2019)</p>
            <p>There are different levels of autonomous vehicles:</p>
            <ul>
              <li>Level 1 since 1950, provides computer assistance for simple driver functions e.g. ABS, cruise control, Stability Control).
            </li>
              <br>
              <li>Level 2 since 2000, provides partial automation of one feature at a time e.g. automatic emergency breaking AEB.
            </li>
              <br>
               <li>Level 3 available now, provides two or more simultaneous functions e.g. cruise control and lane keeping.
            </li>
              <br>
              <li>Level 4 is in testing and will result in most driving functions being automated with the need for human intervention only in unusual circumstances. This automation will allow drivers to read and relax during their journeys.
            </li>
              <br>
              <li>Level 5 from 2060+ and will be fully autonomous. All driving functions will be fully computer controlled with absolutely no human intervention. Not even a steering wheel. The driver could sleep during their journey.
            </li>
            <p style="margin-left:10%; margin-right:10%;">The scenarios for convenience and quality-of-life improvements are limitless. The elderly and the physically disabled would have independence. If your kids were at summer camp and forgot their bathing suits and toothbrushes, the car could bring them the missing items. You could even send your dog to a veterinary appointment. But the real promise of autonomous cars is the potential for dramatically lowering CO2 emissions. (Synopsys 2019)</p>
            <p>The Three Revolutions in Urban Transportation study produced by the University of California, Davis, and the Institute for Transportation and Development Policy, concluded that if society adopts electric vehicles, autonomous vehicles and ride sharing concurrently by 2050, this could lower the CO2 from 4,600 megatonnes to 500 megatonnes per year. That’s an 80% cut in emissions worldwide.</p>
            <p>It is estimated that the introduction of fully autonomous vehicles will have a major economic impact and affect many industries, not just the automotive industry. The following industries are set to be impacted one way or another; Personal travel, Public sector, Real Estate, Energy suppliers, Healthcare, Freight, Insurance, Telecommunications, just to name a few. Within each of the mentioned industries, there is a wide range of jobs that may prosper and some that will decline or cease completely. That means potentially high unemployment rates but also the opportunities for upskilling to keep up with the inevitable changes coming our way in the technology sectors. Some obvious contenders of being made redundant by autonomous cars are independent taxi services, Lyft and Uber drivers even regional flights may become a less favoured option due to the availability of hiring or buying an AV to drive you without the hassle of parking, checking in, security etc.</p>
           <p style="margin-left:10%; margin-right:10%;">Just like the computer, and the car before that, autonomous vehicles will send substantial and numerous shock waves through the world economy. You would be hard pressed to find an industry that will not be impacted (for good or for bad) by autonomous vehicles. Importantly, the economic impacts of the autonomous car will be magnified and accelerated by two parallel innovations: the electric car and mobility-as-a-service (MaaS). Each of these technologies is important and significant on its own. But together these technologies create a virtuous cycle the will expand their respective impact far beyond anything that would be achieved on their own. (Economic Impact 2018). </p>
            <p>Personally, having access to a fully autonomous car would be life-changing. The convenience of being driven through peak-hour traffic and only having to focus on finishing my book or study, would result in a stress-free journey. I will save time as there will be no need to worry about finding a car park. The option of being driven interstate to see my family, subject to available infrastructure, instead of getting on a plane, with the ability to sleep all the way there, would be brilliant. These types of cars would help my elderly family members and friends and eventually myself, to keep our independence in our aging years.</p>
            <p>Having said all that, I wouldn’t use an autonomous car until they had been cleared as 100% reliable and safe. With so much computerisation involved, they are susceptible to hacking and malfunction. If I had the choice between a Level 5, fully automated with no access to a steering wheel and a Level 4, most functions automated except under unusual circumstances, I would choose Level 4, as I don’t completely trust the way the world is heading in relation to the advancements in technology. I feel like it is about to supersede the need for humans in every sector. Sometimes it’s important to stop and look around at what we’ve got before it’s gone forever.</p>
              <p>ADD REFERENCES</p>
              <p>
             <centre><img src="img/NLP.png" alt="NLP" width="460" height="345">
               </p></centre>

              <h1>Natural Language processing and chatterbots</h1>

</p>

<p>Natural Language Processing (NLP) is a branch of Artificial Intelligence

    which allows computers to break down, decipher and make sense of the human

    language in a way that is useful in tasks such as making appointments,

    spell checking, generating responses and social media monitoring. NLP is

    the power behind such applications as Google Translate, Microsoft Word, OK

    Google, Siri, Alexa, and Cortana. NLP is used in email filters, data and

    text analysis, predictive text and digital phone calls.

</p>

<p>

    Natural Language Processing is the language that allows chatbots to

    understand your messages and respond, it provides the intent, context and

    meaning to text-based user inputs so that AI can come up with the best

    response. An NLP chatbot can give the users a feeling that they are having

    a conversation rather than going through a limited set of options and menus

    to reach their end goal.

</p>

<p>

   <p style="margin-left:10%; margin-right:10%;">
        ‘NLP is widely implemented to chat with customers and listen to

        conversations to understand sentiments, topics of interest, answer

        questions, and filter fake and toxic content.’ (Dataversity 2021)</p style="margin-left:10%; margin-right:10%;">

</p>

<p>

    With advances in Deep Learning and higher computer capabilities NLP

    technology has been progressing so rapidly that data scientists have had to

    continually learn new machine learning techniques to keep up, but since the

    development of the current NLP architecture - attention based networks -

    data scientists will finally have that time to catch up.

</p>

<p>

    Attention based networks started to become popular from 2015 onwards.

    Attention based networks are a type of neural network that allows the focus

    to be on a specific subset of data input, specifically what you want the

    network to pay attention to. From 2017 a specific type of attention based

    network called The Transformer Model has been especially dominant in modern

    NLP architecture. An example of a Transformer Model is BERT, a machine

    learning model developed by Google in 2018.

</p>

<p>

    BERT - Bidirectional Encoder Representations from Transformers, is a

    machine learning framework designed to help computers understand the

    meaning of vague and confusing language in text by using the surrounding

    text to establish context. The BERT framework was pre-trained using text

    from Wikipedia and can be fine-tuned with question-and-answer datasets.

</p>

<p>

    One of the focuses of NLP in the next few years will be on customer

    service, specifically with the integration of virtual customer assistants

    or chatbot technology. It is estimated that a quarter of customer service

    jobs will be moved over to this technology in 2020.

</p>

<p>

    The current global health crisis has accelerated customer adoption of

    touchless AI systems like voice assistants.

</p>

<p>

 <p style="margin-left:10%; margin-right:10%;">

        “More than three-quarters of customers (77%) expect to increase the use

        of touchless interfaces to avoid direct interactions with humans or

        touchscreens during COVID-19, and 62% will continue to do so

        post-COVID”.

    - (IT Pro 2020)</p style="margin-left:10%; margin-right:10%;">

</p>

<p>


  </p>

<p>
</p>

<p>

    NLP is a powerful tool for productivity. It will allow us to work smarter

    and faster with fewer mistakes. Chatbots used for customer service and in

    financial institutions allow customers to get immediate answers to their

    questions no matter the time of day or day of the week. Due to advances in

    machine learning techniques, chatbots can even detect a user’s intention.

    It can provide instant links to instructions and give predefined answers to

    a customer’s questions. It can handle mundane and routine tasks such as

    repetitive questions, moderating comments and classifying emails, which

    will improve user satisfaction. Chatbots can respond to billions of demands

    at the same time making these processes faster and more cost efficient.

</p>

<p>

    Ever since the industrial revolution, there has been an underlying fear

    about machines taking jobs away from humans. Many people still like the

    human interaction that comes with face to face contact and conversation

    with humans.

</p>

<p>

    Chatbots are impersonal and lack human warmth. How long will it be before

    you never get to talk to a human voice at the end of a telephone. Jobs

    using speech are at the most risk of being made redundant with these new

    technologies.

</p>

<p>

    Will Google Translate eventually replace translators? Will Siri and Alexa

    replace workplace assistants? Or will they just be of added benefit? The

    future is here, and it is a bit scary but will certainly be efficient.

</p>

<p>
</p>

<p>

    Today I used ‘Hey Siri’ for the first time on my iPhone. It wasn’t a huge

    learning curve; I just went into the settings and activated the ‘Listen for

    Hey Siri’. I’ve been playing around with it today. ‘Hey Siri, play

Paperback Writer’. <em></em>    <em>Ding Ding. Here’s Paperback Writer by The Beatles</em>. There it was.

Brilliant. ‘Hey Siri. Play Pauline Vs Margaret’. <em></em>    <em>Ding Ding. Here’s Naked by Ella Mai</em>. The actual song title is

    Margaret Vs Pauline, so it was a bit hit and miss on deciphering the intent

    of my request and possibly also my accent and tone but was still brilliant.

</p>

<p>

    In writing this report on natural language processing I have been using

    Microsoft Word’s rewrite suggestions option.

</p>

<p>

   <p style="margin-left:10%; margin-right:10%;">

        Susan Hendrich, Microsoft’s group program manager of AI and NLP for

        Office, told VentureBeat that Rewrite Suggestions uses a

        Transformer-based model, and that all new features were developed in

        conjunction with Microsoft Research.

 

 

   - (VentureBeat 2020)</p style="margin-left:10%; margin-right:10%;">

</p>

<p>

    In researching this report, I googled ‘natural language processing for the

    elderly’ and one of the results was a paper exploring the use of natural

    language processing to predict loneliness in older community dwelling

    adults. Another article talked about speech analysis detecting early

    linguistic signs of cognitive decline in a population of elderly

    individuals. Could Siri or a counterpart of Siri read the local newspaper

    to my elderly parents and other friends or family members? Could I

    eventually have a natural language processing Assistant who will write a

    book with me or play accompaniment on an instrument or harmonise when I’m

    singing Paperback Writer? The possibilities seem endless.

</p>

<p>

   <font size="1"></font><strong>References:</strong>

</p>

<p>

    Baidu Research 2019, <em></em><em>Baidu Research</em>, research.baidu.com,

    viewed 3 April 2021, &lt;

    <a href="http://research.baidu.com/Blog/index-view?id=121" target="_blank">

        http://research.baidu.com/Blog/index-view?id=121

    </a>

    &gt;.

</p>

<p>

Heek, NF 2017, <em></em>    <em>How chatbots are killing jobs (and creating new ones)</em>,

    VentureBeat.

</p>

<p>

    Hightower, M 2020, <em></em><em>High-Level History of NLP Models</em>,

    Medium, viewed 3 April 2021, &lt;

    <a

        href="https://towardsdatascience.com/high-level-history-of-nlp-models-bc8c8b142ef7"

        target="_blank"

    >

        https://towardsdatascience.com/high-level-history-of-nlp-models-bc8c8b142ef7

    </a>

    &gt;.

</p>

<p>

IT Pro 2020, <em></em>    <em>Natural Language Processing: the future of the enterprise</em>, IT PRO.

</p>

<p>

Johnson, K 2020, <em></em>    <em>Microsoft’s AI-powered Editor can generate rewrite suggestions</em>,

    VentureBeat, viewed 3 April 2021, &lt;

    <a

        href="https://venturebeat.com/2020/03/30/microsofts-ai-powered-editor-can-generate-rewrite-suggestions/"

        target="_blank"

    >

        https://venturebeat.com/2020/03/30/microsofts-ai-powered-editor-can-generate-rewrite-suggestions/

    </a>

    &gt;.

</p>

<p>

Kaur Gill, J 2019, <em></em>    <em>Evolution and Future of Natural Language Processing (NLP)</em>,

    XenonStack.

</p>

<p>

LudKevich, B 2020, <em></em>    <em>What is BERT (Language Model) and How Does It Work?</em>,

    SearchEnterpriseAI.

</p>

<p>

Talby, D 2020, <em></em>    <em>Four Predictions for Natural Language Processing in 2021</em>,

    DATAVERSITY, viewed 3 April 2021, &lt;

    <a

        href="https://www.dataversity.net/four-predictions-for-natural-language-processing-in-2021/"

        target="_blank"

    >

        https://www.dataversity.net/four-predictions-for-natural-language-processing-in-2021/#

    </a>

    &gt;.

</p>

<p>

The Hugging Face Team 2020, <em></em>    <em>BERT — transformers 2.8.0 documentation</em>, huggingface.co.

      </p></font>

          </article>
        </div>
            </main>
          <footer>
              <ul class="footer-links-main">
                    <a href="index.html">Home
                  </a>
                  <br>
                  <br>
                  <a href="about.html">Contact the Team
                </a>
              </ul>
               <div class="wrapper">
          </footer>
          </div>
            </body>
          </html>
© 2021 GitHub, Inc.
Terms
Privacy
Security
Status
Docs
Contact GitHub
Pricing
API
Training
Blog
About
